

# ğŸŒŸ PulseMind AI
### Emotion-Aware Agentic AI with Text & Voice Input

PulseMind AI is a **multimodal, emotion-aware agentic AI system** that analyzes **human emotions from text and voice inputs** and generates **intelligent, context-aware decisions** to support productivity, stress management, and mental well-being.

This project demonstrates a **real-world end-to-end AI application**, combining NLP, speech recognition, agent-based reasoning, REST APIs, and an interactive frontend.

---

## ğŸ“Œ Project Overview

PulseMind AI allows users to:
- Enter **text** describing their feelings  
- Or use **voice input (earphone microphone)**  
- Detect emotions using a **pretrained NLP model**
- Apply an **agentic decision engine**
- Receive actionable AI-generated suggestions

---

## ğŸ§  Working Architecture

```

User (Text / Voice)
â†“
Streamlit Frontend (UI)
â†“
FastAPI Backend (API Layer)
â†“
Emotion Detection Model (NLP)
â†“
Agentic Decision Engine
â†“
AI Recommendation / Action

```

### ğŸ”¹ Text Flow
```

Text Input
â†’ NLP Emotion Model
â†’ Emotion + Confidence
â†’ Agentic Decision

```

### ğŸ”¹ Voice Flow
```

Voice Input (Mic)
â†’ Speech-to-Text
â†’ NLP Emotion Model
â†’ Agentic Decision

```

---

## ğŸ§© Folder Architecture

```

PulseMind-AI/
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py                # FastAPI backend (text + voice endpoints)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                 # Streamlit UI
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ text_emotion.py        # Text emotion detection model
â”‚   â””â”€â”€ voice_input.py         # Voice input (speech recognition)
â”‚
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ decision_engine.py     # Agentic AI logic
â”‚
â”œâ”€â”€ utils/                     # Helper utilities (future use)
â”‚
â”œâ”€â”€ requirements.txt           # Required libraries
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

---

## âš™ï¸ Libraries & Tools Used

### ğŸ”¹ Backend
- **FastAPI** â€“ REST API framework
- **Uvicorn** â€“ ASGI server

### ğŸ”¹ AI / ML
- **Transformers (HuggingFace)** â€“ NLP model inference
- **PyTorch** â€“ Deep learning backend
- **SpeechRecognition** â€“ Voice-to-text conversion
- **PyAudio** â€“ Microphone audio capture

### ğŸ”¹ Frontend
- **Streamlit** â€“ Interactive UI
- **Requests** â€“ API communication

### ğŸ”¹ Other
- Python 3.10+
- Git & GitHub

---

## ğŸ¤– AI Model Used

### ğŸ§  Text Emotion Detection Model

**Model Name:**
```

j-hartmann/emotion-english-distilroberta-base

````

**Why this model?**
- Pretrained on emotion-labeled English text
- Lightweight and fast
- High accuracy for emotion classification
- Suitable for real-time inference

**Detected Emotions Include:**
- Anger
- Sadness
- Fear
- Joy
- Neutral

---

## ğŸ§  Agentic Decision Engine

The agentic layer analyzes:
- Detected emotion
- Confidence score

Based on rules, it decides:
- Suggest a break
- Encourage user
- Normal continuation

Example:
```json
{
  "action": "suggest_break",
  "message": "You seem stressed. Take a short break and revisit the task calmly."
}
````

---

## ğŸ–¥ï¸ Frontend Description (Streamlit)

The frontend provides:

* âœï¸ Text input area
* ğŸ™ï¸ Voice input button
* Emotion visualization
* AI decision display

It communicates with backend endpoints:

* `/analyze_text`
* `/analyze_voice`

---

## ğŸŒ Backend API Endpoints

### ğŸ”¹ Root

```
GET /
```

Returns backend health status.

---

### ğŸ”¹ Analyze Text Emotion

```
POST /analyze_text
```

**Input**

```json
{
  "text": "I am feeling very stressed and tired today"
}
```

---

### ğŸ”¹ Analyze Voice Emotion

```
POST /analyze_voice
```

* Uses system microphone
* Converts speech â†’ text
* Analyzes emotion

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Create & Activate Environment

```bash
conda create -n guduenv python=3.11 -y
conda activate guduenv
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run Backend (Terminal 1)

```bash
uvicorn backend.main:app --reload
```

Backend URL:

```
http://127.0.0.1:8000
```

---

### 4ï¸âƒ£ Run Frontend (Terminal 2)

```bash
streamlit run frontend/app.py
```

Frontend URL:

```
http://localhost:8501
```
<img width="1917" height="877" alt="Screenshot 2026-01-01 201503" src="https://github.com/user-attachments/assets/b6d99394-cbdc-4047-807d-9115b4bd1ada" />
<img width="1919" height="887" alt="Screenshot 2026-01-01 201436" src="https://github.com/user-attachments/assets/f8330664-84c9-4907-a0a4-1b343a305886" />
<img width="1919" height="873" alt="Screenshot 2026-01-01 200945" src="https://github.com/user-attachments/assets/dfa50e66-05f6-43d0-9b0e-d17fe748d13a" />

---

## ğŸ¯ Real-World Use Cases

* Mental health awareness tools
* Stress & burnout detection
* Emotion-aware productivity assistants
* Human-centric AI systems
* Affective computing research

---

## ğŸš€ Future Enhancements

* Voice response (Text-to-Speech)
* Emotion history tracking
* Burnout score visualization
* Cloud deployment (AWS / Azure)
* Mobile-friendly UI
* Advanced agent reasoning

---

## ğŸ‘¤ Author

**Parthasarathi Behera**
Aspiring AI Engineer | Data Science & Generative AI Enthusiast






